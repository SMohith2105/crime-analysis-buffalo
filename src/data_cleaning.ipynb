{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "\n",
    "### Problem Statement:\n",
    "The city of Buffalo experiences a wide range of crime incidents, but sometimes the data available for certain incidents is incomplete or missing crucial information, making it challenging to determine the exact type of crime that occurred. In such cases, predicting the type of crime based on limited or incomplete crime-related data is crucial for effective decision-making and resource allocation by law enforcement.\n",
    "\n",
    "This project aims to build a machine learning classification model capable of predicting the type of crime incident based on partial information such as time of day, location, and brief descriptions. This model will help in identifying the nature of crimes when details are scarce or when forecasting future incidents based on historical patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://data.buffalony.gov/resource/d6g9-xbgu.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3:\n",
    "### Data Retrieval Process\n",
    "The data extraction process was carried out using a REST API request, iterating through the dataset in a paginated manner to retrieve crime records. Below is a detailed breakdown of the process:\n",
    "1. **Pagination and Data Fetching**:  \n",
    "   - The dataset was accessed in chunks of **1000 records per request** using pagination with `$limit` and `$offset` to handle large amounts of data. The **`offset`** tracked how many records had been retrieved, allowing subsequent requests to fetch the next batch.\n",
    "\n",
    "2. **Cutoff Date for Data Filtering**:  \n",
    "   - The Buffalo crime data website indicates that data before **2009** is unreliable. Therefore, a **cutoff date** of **January 1, 2009** was applied. Records were retrieved in descending order based on **`incident_datetime`**, ensuring that only data from **2009** onwards was collected.\n",
    "\n",
    "3. **Data Processing**:  \n",
    "   - After converting the **`incident_datetime`** field to a **datetime** format, each batch was checked to filter out records before **2009**. Once data from earlier than **2009** was encountered, further fetching was stopped.\n",
    "\n",
    "4. **Combining Data Chunks**:  \n",
    "   - The data retrieved in chunks was combined into a single **DataFrame**, containing crime data from **January 1, 2009** onwards, ensuring the dataset's reliability based on the source's guidelines.\n",
    "\n",
    "This approach ensures that only reliable crime data from **2009** onwards is used for analysis, following the cutoff requirements from the Buffalo crime data website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "offset = 0\n",
    "limit = 1000  # Adjust this value as needed\n",
    "cutoff_date = datetime(2009, 1, 1)  # Set the cutoff date to the end of 2009\n",
    "\n",
    "while True:\n",
    "    params = {\n",
    "        '$limit': limit,\n",
    "        '$offset': offset,\n",
    "        '$order': 'incident_datetime DESC'  # Sort by incident_datetime in descending order\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    df_page = pd.DataFrame(data)\n",
    "    \n",
    "    if df_page.empty:\n",
    "        break\n",
    "    \n",
    "    # Convert incident_datetime to datetime objects\n",
    "    df_page['incident_datetime'] = pd.to_datetime(df_page['incident_datetime'])\n",
    "    \n",
    "    # Check if we've reached data before or equal to 2009\n",
    "    if df_page['incident_datetime'].min() <= cutoff_date:\n",
    "        # Filter out rows after 2009\n",
    "        df_page = df_page[df_page['incident_datetime'] <= cutoff_date]\n",
    "        df_list.append(df_page)\n",
    "        break\n",
    "    \n",
    "    df_list.append(df_page)\n",
    "    offset += limit\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incident_description\n",
       "Buffalo Police are investigating this report of a crime.  It is important to note that this is very preliminary information and further investigation as to the facts and circumstances of this report may be necessary.    250527\n",
       "Buffalo Police are investigating this report of a crime. It is important to note that this is very preliminary information and further investigation as to the facts and circumstances of this report may be necessary.       5177\n",
       "LARCENY/THEFT                                                                                                                                                                                                                 2012\n",
       "BURGLARY                                                                                                                                                                                                                      1061\n",
       "ASSAULT                                                                                                                                                                                                                        704\n",
       "SEXUAL ABUSE                                                                                                                                                                                                                   146\n",
       "UUV                                                                                                                                                                                                                            111\n",
       "RAPE                                                                                                                                                                                                                            72\n",
       "ROBBERY                                                                                                                                                                                                                         36\n",
       "CRIM NEGLIGENT HOMICIDE                                                                                                                                                                                                         22\n",
       "THEFT OF SERVICES                                                                                                                                                                                                               12\n",
       "AGG ASSAULT ON P/OFFICER                                                                                                                                                                                                         2\n",
       "AGGR ASSAULT                                                                                                                                                                                                                     2\n",
       "MURDER                                                                                                                                                                                                                           2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['incident_description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "As we can see above, there are two same incident descriptions with an extra space in one of them in the incident_description column.\n",
    "So, this can be rectified using regex. 'r\\s+' identifies unwanted spaces in the middle of the text and the rreplace method replaces it with a single space.\n",
    "'''\n",
    "df['incident_description'] = df['incident_description'].str.replace(r'\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['incident_description']=df['incident_description'].str.replace('Buffalo Police are investigating this report of a crime. It is important to note that this is very preliminary information and further investigation as to the facts and circumstances of this report may be necessary.','under investigation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['incident_description']=df['incident_description'].str.replace('Buffalo Police are investigating this report of a crime. It is important to note that this is very preliminary information and further investigation as to the facts and circumstances of this report may be necessary.','under investigation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace('UNKNOWN',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by='incident_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['incident_datetime'].dt.year\n",
    "df['month'] = df['incident_datetime'].dt.month\n",
    "df['day'] = df['incident_datetime'].dt.day\n",
    "df['weekday'] = df['incident_datetime'].dt.weekday \n",
    "df['hour'] = df['incident_datetime'].dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['incident_type_primary']=df['incident_type_primary'].str.lower()\n",
    "df['parent_incident_type']=df['parent_incident_type'].str.lower()\n",
    "df['address_1']=df['address_1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude']=df['latitude'].astype('float64')\n",
    "df['longitude']=df['longitude'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case_number                     0\n",
       "incident_datetime               0\n",
       "incident_type_primary           0\n",
       "incident_description            0\n",
       "parent_incident_type            0\n",
       "hour_of_day                     0\n",
       "day_of_week                     0\n",
       "address_1                      33\n",
       "city                            0\n",
       "state                           0\n",
       "location                     5989\n",
       "latitude                     5989\n",
       "longitude                    5989\n",
       "created_at                 189318\n",
       "zip_code                     3277\n",
       "neighborhood                 5975\n",
       "council_district             2286\n",
       "council_district_2011        3331\n",
       "census_tract                 5882\n",
       "census_block_group           5882\n",
       "census_block                 5882\n",
       "census_tract_2010           19429\n",
       "census_block_group_2010     19461\n",
       "census_block_2010           19431\n",
       "police_district              5889\n",
       "tractce20                    5882\n",
       "geoid20_tract                5882\n",
       "geoid20_blockgroup           5882\n",
       "geoid20_block                5882\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As we can see created_at column has too many null values, hence dropping that column\n",
    "df_filtered=df.drop(columns=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The remaining null values are very less in number when compared to the total size of the dataset, hence we can drop it\n",
    "df_filtered.dropna(axis='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize incident types into broader crime categories (sexual, assault, vehicle, theft, murder)\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].str.lower()\n",
    "\n",
    "sexual_crimes = ['other sexual offense','sexual assault', 'rape', 'sexual abuse', 'sodomy']\n",
    "assault_crimes=['agg assault on p/officer', 'aggr assault', 'assault']\n",
    "vehicle_crimes=['theft of vehicles', 'uuv','theft of vehicle']\n",
    "theft_crimes=['burglary', 'larceny/theft','robbery', 'theft of services','theft', 'breaking & entering']\n",
    "murder_crimes=['crim negligent homicide', 'homicide', 'manslaughter', 'murder']\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].replace(sexual_crimes, 'sexual crime')\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].replace(assault_crimes, 'assault crime')\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].replace(vehicle_crimes, 'vehicle crime')\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].replace(theft_crimes,'theft crimes')\n",
    "df_filtered['incident_type_primary'] = df_filtered['incident_type_primary'].replace(murder_crimes,'murder crimes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert crime data to GeoDataFrame\n",
    "gdf_crimes = gpd.GeoDataFrame(\n",
    "    df_filtered, \n",
    "    geometry=gpd.points_from_xy(df_filtered.longitude, df_filtered.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
